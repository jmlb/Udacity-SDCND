{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from skimage import morphology\n",
    "from collections import deque\n",
    "%matplotlib inline\n",
    "\n",
    "# Display intermediate steps for image processing and lane finding\n",
    "showMe = 0\n",
    "\n",
    "\n",
    "def display(img, title, color=1):\n",
    "    '''\n",
    "    display images\n",
    "    img: rgb or grayscale\n",
    "    title: figure title\n",
    "    color: show image in color(1) or grasycale(0)\n",
    "    '''\n",
    "    if color:\n",
    "        plt.imshow(img)\n",
    "    else:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMS Error of Camera calibration: 1.030\n",
      "This number must be between 0.1 and 1.0\n"
     ]
    }
   ],
   "source": [
    "def camera_calibration(folder, nx, ny, showMe=0):\n",
    "    '''\n",
    "    find (x, y) locations of all corners using openCV findChessBoardCorners\n",
    "    folder: directory of the calibration images\n",
    "    nx: expected number of corners along the x direction\n",
    "    ny: expected number of corners along the y direction\n",
    "    return a dictionary:\n",
    "        ret: RMS Error of the calibration\n",
    "        mtx: the camera matrix\n",
    "        dist: distorsion coefficients\n",
    "        rvecs: rotation vectors\n",
    "        tvecs: translation vectors\n",
    "    '''\n",
    "    # Store object points and image points from all the images\n",
    "    objpoints = [] #3D points in real world space\n",
    "    imgpoints = [] #2D points in image plane\n",
    "    #Prepare object points, like (0,0,0), (1, 0,0)\n",
    "    objp = np.zeros((nx * ny, 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx,0:ny].T.reshape(-1,2) #x, y coordinate\n",
    "        \n",
    "    assert len(folder) != 0, 'No file found in folder'\n",
    "        \n",
    "    for fname in folder:\n",
    "        img = cv2.imread(fname)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "        img_sz = gray.shape[::-1]\n",
    "            \n",
    "        if ret:\n",
    "            imgpoints.append(corners)\n",
    "            objpoints.append(objp)\n",
    "            if showMe:\n",
    "                draw_corners = cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "                display(draw_corners, 'Found all corners: {} '.format(ret))\n",
    "\n",
    "    if len(objpoints) == len(imgpoints) and len(objpoints) != 0:\n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_sz, None, None)\n",
    "        return {'ret': ret, 'cameraMatrix': mtx, 'distorsionCoeff': dist, \\\n",
    "                    'rotationVec': rvecs, 'translationVec': tvecs}\n",
    "    else:\n",
    "        raise Error('Camera Calibration failed')\n",
    "\n",
    "\n",
    "    \n",
    "def correction(image, calib_params, showMe=0):\n",
    "    '''\n",
    "    Distorsion correction\n",
    "    calib_params: calibration parameters returned by camera_calibration()\n",
    "    '''\n",
    "    corrected = cv2.undistort(image, calib_params['cameraMatrix'], calib_params['distorsionCoeff'], None, \n",
    "                         calib_params['cameraMatrix'])\n",
    "    if showMe:\n",
    "        display(image, 'Original', color=1)\n",
    "        display(corrected, 'After correction', color=1)\n",
    "\n",
    "        \n",
    "\n",
    "nx = 9 #number of corners in a row\n",
    "ny = 6 #numbers or corners in a column\n",
    "folder_calibration = glob.glob(\"camera_cal/calibration*.jpg\") #list of chessboard image files\n",
    "calib_params = camera_calibration(folder_calibration, nx, ny, showMe=0)\n",
    "# for a good calibration ret must be between 0.1 and 1.0\n",
    "print('RMS Error of Camera calibration: {:.3f}'.format(calib_params['ret']) )\n",
    "print('This number must be between 0.1 and 1.0')\n",
    "\n",
    "#Show example distorsion correction\n",
    "imgs_tests = glob.glob(\"test_images/*.jpg\")\n",
    "original_img = np.random.choice(imgs_tests)\n",
    "original_img = cv2.imread(\"test_images/test5.jpg\")\n",
    "original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n",
    "corr_img = correction(original_img, calib_params, showMe=showMe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImageProcess():\n",
    "    '''\n",
    "    Processing methods of original images\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def gaussianBlur(self, img, k_sz=5):\n",
    "        # Useful to remove salt'n pepper noise - NOT USE HERE\n",
    "        img = cv2.GaussianBlur(img, (k_sz, k_sz), 0)\n",
    "        return img\n",
    "    \n",
    "    \n",
    "    def directional_gradient(self, img, direction='x', thresh=[0, 255]):\n",
    "        '''\n",
    "        Gradient along vertical or horizontal direction using OpenCV Sobel \n",
    "        img: Grayscale\n",
    "        direction: x(horizontal) or y(vertical) for gradient direction\n",
    "        thresh: apply threshold on pixel intensity of gradient image\n",
    "        output is a binary image\n",
    "        '''\n",
    "        if direction == 'x':\n",
    "            sobel = cv2.Sobel(img, cv2.CV_64F, 1, 0)\n",
    "        elif direction == 'y':\n",
    "            sobel = cv2.Sobel(img, cv2.CV_64F, 0, 1)\n",
    "        \n",
    "        sobel_abs = np.absolute(sobel)  #absolute value\n",
    "        scaled_sobel = np.uint8(sobel_abs * 255/np.max(sobel_abs)) #turn sobel to 8bit image 0-255 intensity range\n",
    "        binary_output = np.zeros_like(sobel)\n",
    "        binary_output[(scaled_sobel>= thresh[0]) & (scaled_sobel <= thresh[1]) ] = 1 #generate binary\n",
    "        \n",
    "        return binary_output\n",
    "\n",
    "\n",
    "    def mag_gradient(self, img, thresh=[0, 255]):\n",
    "        '''\n",
    "        Magnitude of gradient : sqrt(gradx**2 + grady**2)\n",
    "        img: RGB or Grayscale image\n",
    "        thresh: apply threshold on pixel intensity of the gardient magnitude\n",
    "        output is a binary image\n",
    "        '''\n",
    "        sobelx = cv2.Sobel(img, cv2.CV_64F, 1, 0)  #gradient along x\n",
    "        sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1) #gradient along y\n",
    "        gradient_mag = np.sqrt( np.square(sobelx) + np.square(sobely)) # norm of gradient\n",
    "        scaled_gradient_mag = np.uint8(gradient_mag * 255/np.max(gradient_mag)) #turn sobel to 8bit image 0-255 intensity range\n",
    "        binary_output = np.zeros_like(gradient_mag)\n",
    "        binary_output[(scaled_gradient_mag >= thresh[0]) & (scaled_gradient_mag <= thresh[1]) ] = 1 #thresholding\n",
    "        \n",
    "        return binary_output\n",
    "\n",
    "\n",
    "    def gradient_direction(self, img, thresh=[0, 90], ksize=3):\n",
    "        '''\n",
    "        Direction of gradient: arctan(grady/gradx)\n",
    "        img: RGB or Grayscale image\n",
    "        thresh: apply threshold on gradient direction in degrees (0, 90)\n",
    "        ksize: kernel size (can only be a odd number)\n",
    "        output is a binary image\n",
    "        '''\n",
    "        sobelx = cv2.Sobel(img, cv2.CV_64F, 1,0, ksize) #gradient along x\n",
    "        sobely = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize) #gradient along y\n",
    "        gradient_dir = np.arctan2( sobely, sobelx)\n",
    "        thresh = [thresh[0] * np.pi/180, thresh[1] * np.pi/180] #convert threshold from degree to radian\n",
    "        binary_output = np.zeros_like(gradient_dir)\n",
    "        binary_output[(gradient_dir>= thresh[0]) & (gradient_dir <= thresh[1]) ] = 1 #thresholding\n",
    "        \n",
    "        return binary_output\n",
    "\n",
    "    \n",
    "    def color_binary(self, img, dst_format='HLS', ch=2, ch_thresh=[0,255]):\n",
    "        '''\n",
    "        Color thesholding on channel ch\n",
    "        img: RGB\n",
    "        dst_format: destination format (HLS or HSV)\n",
    "        ch_thresh: pixel intensity threshold on channel ch\n",
    "        output is a binary image\n",
    "        '''\n",
    "        if dst_format == 'HSV':\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "            ch_binary = np.zeros_like(img[:,:, int(ch-1)])\n",
    "        else:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "            ch_binary = np.zeros_like(img[:,:, int(ch-1)])\n",
    "            ch_binary[(img[:,:,int(ch-1)] >= ch_thresh[0]) & (img[:,:,int(ch-1)]<= ch_thresh[1])] = 1\n",
    "        \n",
    "        return ch_binary\n",
    "    \n",
    "    \n",
    "    \n",
    "    def image_correction(self, img, cal_params):\n",
    "        '''\n",
    "        correct image from camera distorsion\n",
    "        img: original image RGB format\n",
    "        cal_params: calibration parameters of camera (Camera Matrix and distorsion Coefficients)\n",
    "        return: undistorted image\n",
    "        '''\n",
    "        dst = cv2.undistort(img, cal_params['cameraMatrix'], \\\n",
    "                            cal_params['distorsionCoeff'], None, \\\n",
    "                            cal_params['cameraMatrix'])\n",
    "        return dst\n",
    "        \n",
    "    \n",
    "    def convert2_rgb(self, img):\n",
    "        '''\n",
    "        convert image to RGB\n",
    "        img: RGB image\n",
    "        '''\n",
    "        try:\n",
    "            rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            return rgb\n",
    "        except:\n",
    "            print('image cannpot be converted to RGB')\n",
    "    \n",
    "    \n",
    "    def convert2_gray(self, img):\n",
    "        '''\n",
    "        convert image to gray\n",
    "        img: RGB image\n",
    "        '''\n",
    "        if len(img.shape) == 3:\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "            return gray\n",
    "        elif len(img.shape) == 2: #img channel already squashed\n",
    "            return img\n",
    "\n",
    "    \n",
    "    def birdView(self, img, M):\n",
    "        '''\n",
    "        Transform image to birdeye view\n",
    "        img: binary image\n",
    "        M: transformation matrix\n",
    "        return a warped image\n",
    "        '''\n",
    "        \n",
    "        img_sz = (img.shape[1], img.shape[0])\n",
    "        img_warped = cv2.warpPerspective(img, M, img_sz, flags=cv2.INTER_LINEAR)\n",
    "        \n",
    "        return img_warped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Line Detection and fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "from scipy.stats import iqr\n",
    "\n",
    "\n",
    "class Line():\n",
    "    '''\n",
    "    extract pixels associated with lanes and fit them to 2nd order polynomial function\n",
    "    '''\n",
    "\n",
    "    def __init__(self,buffer_sz, showMe):\n",
    "        # was the line detected in the last iteration? \n",
    "        self.buffer_sz = buffer_sz\n",
    "        #x values of hotpixels for the last n(=buffer_sz) frames\n",
    "        self.allx = deque([], maxlen=self.buffer_sz)  \n",
    "        #y values of hotpixels for the last n frames\n",
    "        self.ally = deque([], maxlen=self.buffer_sz)\n",
    "        \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.bestfit = {'a0':deque([], maxlen=self.buffer_sz), \n",
    "                        'a1':deque([], maxlen=self.buffer_sz), \n",
    "                        'a2':deque([], maxlen=self.buffer_sz)}\n",
    "        #polynomial coefficients in real space averaged over the last n iterations\n",
    "        self.bestfit_real = {'a0':deque([], maxlen=self.buffer_sz),\n",
    "                                  'a1':deque([], maxlen=self.buffer_sz),\n",
    "                                  'a2':deque([], maxlen=self.buffer_sz)}\n",
    "        #radius of curvature of the line in m\n",
    "        self.radOfCurv_tracker = deque([], maxlen=self.buffer_sz)\n",
    "        self.showMe = showMe\n",
    "        self.starter_centroid = None\n",
    "        self.line_detected = False\n",
    "\n",
    "        \n",
    "        \n",
    "    def MahalanobisDist(self, x, y):\n",
    "        '''\n",
    "        Mahalanobis Distance for bi-variate distribution\n",
    "        '''\n",
    "        covariance_xy = np.cov(x,y, rowvar=0)\n",
    "        inv_covariance_xy = np.linalg.inv(covariance_xy)\n",
    "        xy_mean = np.mean(x),np.mean(y)\n",
    "        x_diff = np.array([x_i - xy_mean[0] for x_i in x])\n",
    "        y_diff = np.array([y_i - xy_mean[1] for y_i in y])\n",
    "        diff_xy = np.transpose([x_diff, y_diff])\n",
    "    \n",
    "        md = []\n",
    "        for i in range(len(diff_xy)):\n",
    "            md.append(np.sqrt(np.dot(np.dot(np.transpose(diff_xy[i]),inv_covariance_xy),diff_xy[i])))\n",
    "        return md\n",
    "\n",
    "    \n",
    "\n",
    "    def MD_removeOutliers(self, x, y, MD_thresh):\n",
    "        '''\n",
    "        Remove pixels outliers using Mahalonobis distance\n",
    "        '''\n",
    "        MD = self.MahalanobisDist(x, y)\n",
    "        threshold = np.mean(MD) * MD_thresh # adjust 1.5 accordingly \n",
    "        nx, ny, outliers = [], [], []\n",
    "        for i in range(len(MD)):\n",
    "            if MD[i] <= threshold:\n",
    "                nx.append(x[i])\n",
    "                ny.append(y[i])\n",
    "            else:\n",
    "                outliers.append(i) # position of removed pair\n",
    "        return (nx, ny)\n",
    "\n",
    "\n",
    "    \n",
    "    def polynomial_fit(self, data):\n",
    "        '''\n",
    "        Perform 2nd order polynomial fit: a0 + a1 x + a2 x**2\n",
    "        data: dictionary with x and y values {'x':[], 'y':[]}\n",
    "        '''\n",
    "        a2, a1, a0 = np.polyfit(data['x'], data['y'], 2)\n",
    "        return {'a0': a0, 'a1': a1, 'a2': a2}\n",
    "\n",
    "\n",
    "    \n",
    "    def find_starter_centroids(self, image, x0, peak_thresh, showMe):\n",
    "        '''\n",
    "        Find starter centroids using histogram\n",
    "        peak_thresh: If peak intensity is below a threshold use histogram on the full height of the image\n",
    "        returns x-position of centroid and peak intensity\n",
    "        '''\n",
    "        #Define window\n",
    "        window = {'x0': x0, 'y0': image.shape[0], 'width':image.shape[1]/2, 'height':image.shape[0]/2}\n",
    "        \n",
    "        #get centroid\n",
    "        centroid, peak_intensity, _ = self.find_centroid(image, peak_thresh, window, showMe)\n",
    "        #if peak intensity smaller than threshold, change window height to full image height\n",
    "        if (peak_intensity < peak_thresh):\n",
    "            window['height']=image.shape[0]\n",
    "            centroid, peak_intensity, _ = self.find_centroid(image, peak_thresh, window, showMe)\n",
    "        return {'centroid': centroid, 'intensity': peak_intensity}\n",
    "\n",
    "    \n",
    "    \n",
    "    def find_centroid(self, image, peak_thresh, window, showMe):\n",
    "        '''\n",
    "        find centroid in a window using histogram of hotpixels\n",
    "        img: binary image\n",
    "        window with specs {'x0', 'y0', 'width', 'height'}\n",
    "            (x0,y0) coordinates of bottom-left corner of window\n",
    "        return  x-position of centroid, peak intensity and hotpixels_cnt in window \n",
    "        '''\n",
    "        #crop image to window dimension\n",
    "        mask_window = image[ round( window['y0'] - window['height']):round(window['y0']), \n",
    "                              round(window['x0']):round(window['x0']+ window['width'])]\n",
    "        histogram = np.sum(mask_window, axis=0)\n",
    "        centroid = np.argmax(histogram)\n",
    "        hotpixels_cnt = np.sum(histogram)\n",
    "        peak_intensity = histogram[centroid]\n",
    "        if peak_intensity <= peak_thresh:\n",
    "            #centroid reading is likely unreliable - take center of box as centroid\n",
    "            #global position of centroid in image\n",
    "            centroid = int( round(window['x0'] + window['width']/2) )\n",
    "            peak_intensity=0\n",
    "        else:\n",
    "            #global position of centroid in image\n",
    "            centroid = int( round(centroid + window['x0']) )\n",
    "        \n",
    "        if showMe:\n",
    "            plt.plot(histogram)\n",
    "            plt.title('Histogram')\n",
    "            plt.xlabel('horizontal position')\n",
    "            plt.ylabel('hot pixels count')\n",
    "            plt.show()\n",
    "            \n",
    "        return (centroid, peak_intensity, hotpixels_cnt)   \n",
    "  \n",
    "\n",
    " \n",
    "    def run_sliding_window(self, image, centroid_starter, sliding_window_specs, showMe=showMe):\n",
    "        '''\n",
    "        Run sliding window from bottom to top of the image and return indexes of the hotpixels associated with lane\n",
    "        image: binary image\n",
    "        centroid_starter: centroid starting location sliding window\n",
    "        sliding_window_specs: ['width', 'n_steps']\n",
    "            width of sliding window\n",
    "            number of steps of sliding window along vertical axis\n",
    "        returns {'x':[], 'y':[]} coordinates of all hotpixels detected by sliding window\n",
    "                coordinate of all centroids recorded but not used yet! \n",
    "                \n",
    "        '''\n",
    "        #assert image.shape[0]%n_steps==0, 'number of steps must be a factor of the image height'\n",
    "        \n",
    "        #Initialize sliding window\n",
    "        window = {'x0': centroid_starter - int(sliding_window_specs['width']/2), 'y0': image.shape[0], \n",
    "                  'width': sliding_window_specs['width'], \n",
    "                  'height': round(image.shape[0]/sliding_window_specs['n_steps'])}\n",
    "\n",
    "        #Initialize log to store coordinates of hotpixels and log to store centroids coordinates at each step\n",
    "        hotpixels_log = { 'x': [], 'y':[]}\n",
    "        centroids_log = []\n",
    "        if showMe:\n",
    "            out_img = (np.dstack((image, image, image) ) * 255).astype('uint8') #convert to uint8\n",
    "        \n",
    "        for step in range(sliding_window_specs['n_steps']):\n",
    "            #Limit lateral position of window: must remains within image width\n",
    "            if (window['x0'] < 0): window['x0'] = 0   \n",
    "            if (window['x0'] + sliding_window_specs['width']) > image.shape[1]: \n",
    "                window['x0'] = image.shape[1] - sliding_window_specs['width']\n",
    "            \n",
    "            centroid, peak_intensity, hotpixels_cnt = self.find_centroid(image, peak_thresh, window, showMe=showMe)\n",
    "            if step == 0:\n",
    "                self.starter_centroid = centroid\n",
    "            #if >60% of window area is filled by hotpixels, increase window width\n",
    "            if hotpixels_cnt/(window['width']*window['height']) > 0.6:\n",
    "                window['width']= window['width']*2\n",
    "                window['x0'] = round(window['x0'] - window['width']/2)\n",
    "                #Make sure window remains within image width\n",
    "                if (window['x0'] < 0): window['x0'] = 0   \n",
    "                if (window['x0'] + window['width']) > image.shape[1]: \n",
    "                    window['x0'] = image.shape[1] - window['width']\n",
    "                centroid, peak_intensity, hotpixels_cnt = self.find_centroid(image, peak_thresh, window, showMe=showMe)\n",
    "\n",
    "            if showMe:\n",
    "                print('peak intensity {}'.format(peak_intensity))\n",
    "                print('This is centroid: {}'.format(centroid))\n",
    "            \n",
    "            # Create a copy of image where all pixels outside window are turned off (=0)\n",
    "            mask_window = np.zeros_like(image)\n",
    "            mask_window[ window['y0']- window['height'] : window['y0'],\n",
    "                                window['x0']:window['x0']+window['width']] \\\n",
    "                    = image[ window['y0']- window['height'] : window['y0'],\n",
    "                                window['x0']:window['x0']+window['width']]\n",
    "            \n",
    "            #Get coordinates of hot pixels in window\n",
    "            hotpixels = np.nonzero( mask_window )\n",
    "            hotpixels_log['x'].extend(hotpixels[0].tolist())\n",
    "            hotpixels_log['y'].extend(hotpixels[1].tolist())\n",
    "            #update record of centroids\n",
    "            centroids_log.append(centroid)\n",
    "           \n",
    "            if showMe:\n",
    "                cv2.rectangle(out_img, \n",
    "                          (window['x0'], window['y0']- window['height']),\n",
    "                          (window['x0']+window['width'], window['y0']),(0,255,0), 2)\n",
    "\n",
    "                plt.imshow(out_img)\n",
    "                plt.show()\n",
    "             \n",
    "            #set next position of window and use standard sliding window width\n",
    "            window['width'] = sliding_window_specs['width']\n",
    "            window['x0'] = round(centroid - window['width']/2)\n",
    "            window['y0'] = window['y0'] - window['height']\n",
    "        \n",
    "        return hotpixels_log\n",
    "\n",
    "    \n",
    "    \n",
    "    def predict_line(self, x0, xmax, coeffs):\n",
    "        '''\n",
    "        Predict road line using polyfit coefficients \n",
    "        x values are in range (x0, xmax)\n",
    "        polyfit coeffs: {'a2': , 'a1': , 'a2': }\n",
    "        returns array of [x, y] predicted points, x along image vertical / y along image horizontal direction\n",
    "        '''\n",
    "        x_pts = np.linspace(x0, xmax-1, num=xmax) #x coordinates are along the vertical axis of the image\n",
    "        #predict y coordinates along the horizontal axis\n",
    "        pred = coeffs['a2']*x_pts**2 + coeffs['a1']*x_pts + coeffs['a0']\n",
    "        \n",
    "        return np.column_stack((x_pts,pred))\n",
    " \n",
    "\n",
    "    \n",
    "    def update_tracker(self, tracker, new_value):\n",
    "        '''\n",
    "        update tracker (self.bestfit or self.bestfit_real or radOfCurv or hotpixels) with new coeffs\n",
    "        new_coeffs is of the form {'a2': val2, 'a1': val1, 'a0': val0}\n",
    "        tracker is of the form {'a2': [val2,...], 'a1': [val1,...], 'a0': [val0,...]}\n",
    "        update tracker of radius of curvature\n",
    "        update allx and ally with hotpixels coordinates from last sliding window \n",
    "        '''\n",
    "        if tracker == 'bestfit':\n",
    "            self.bestfit['a0'].append(new_value['a0'])\n",
    "            self.bestfit['a1'].append(new_value['a1'])\n",
    "            self.bestfit['a2'].append(new_value['a2'])\n",
    "        elif tracker == 'bestfit_real':\n",
    "            self.bestfit_real['a0'].append(new_value['a0'])\n",
    "            self.bestfit_real['a1'].append(new_value['a1'])\n",
    "            self.bestfit_real['a2'].append(new_value['a2'])\n",
    "        elif tracker == 'radOfCurvature':\n",
    "            self.radOfCurv_tracker.append(new_value)\n",
    "        elif tracker == 'hotpixels':\n",
    "            self.allx.append(new_value['x'])\n",
    "            self.ally.append(new_value['y'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    def compute_radOfCurvature(self, coeffs, pt):\n",
    "        '''\n",
    "        compute radius of curvature in meter or pixels\n",
    "        polyfit coeffs is of the form {'a2': val2, 'a1': val1, 'a0': val0}\n",
    "        pt is the x coordinate (position along the vertical axis ) where to evaluate the radius of curvature\n",
    "        '''\n",
    "            \n",
    "        return ((1 + (2*coeffs['a2']*pt + coeffs['a1'])**2)**1.5) / np.absolute(2*coeffs['a2'])\n",
    "                \n",
    "    \n",
    "\n",
    "    def intercept_is_outlier(self, data, elt):\n",
    "        '''\n",
    "        Determine if intercept 'elt' is an outlier when compared to previous 'intercepts' in data\n",
    "        returns True if elt is an outlier\n",
    "        '''\n",
    "        outlier_flag = False\n",
    "        #evaluate if elt is an outlier when data has enough datapoints\n",
    "        if len(data) == self.buffer_sz:\n",
    "            p = np.min(data)-50\n",
    "            q = np.max(data)+50\n",
    "            \n",
    "            if elt < q and elt > p:\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "    \n",
    "    \n",
    "    def is_outlier(self, data, elt):\n",
    "        '''\n",
    "        Determine if 'elt' is an outlier when compared to datapoints in data\n",
    "        Use IQR scheme\n",
    "        returns True if elt is an outlier\n",
    "        NOT USED\n",
    "        '''\n",
    "        outlier_flag = False\n",
    "        #evaluate if elt is an outlier when data has enough datapoints\n",
    "        if len(data) == self.buffer_sz:\n",
    "            q1 = np.percentile(data, 25)\n",
    "            q3 = np.percentile(data, 75)\n",
    "            iqr = q3-q1\n",
    "            if elt < (q3 + 1.5*iqr) and elt > q1 - 1.5*iqr: \n",
    "                return False\n",
    "            else: \n",
    "                return True\n",
    "            \n",
    "\n",
    "        \n",
    "    def approve_line(self, coeffs, xmax):\n",
    "        '''\n",
    "        Approve if detected hotpixels are from a real line road\n",
    "        Scheme: if intercept of bestfitat 0 and xmax(bottom of image) agrees with previous frames, then flag True\n",
    "        output: flag\n",
    "        '''\n",
    "        flag_line = True\n",
    "            \n",
    "        #check if intercepts at top of image is an outlier\n",
    "        if self.intercept_is_outlier(self.bestfit['a0'], coeffs['a0']):\n",
    "            flag_line = False\n",
    "\n",
    "        #check if intercepts at bottom of image is an outlier\n",
    "        #Calculate intercept at bottom of image for n previous frames \n",
    "        intercepts_bottom = np.array(self.bestfit['a2']) * xmax**2 + np.array(self.bestfit['a1']) * xmax \\\n",
    "                        + np.array(self.bestfit['a0'])\n",
    "        #current frame \n",
    "        this_intercept_bottom = coeffs['a2']* xmax**2 + coeffs['a1']* xmax + coeffs['a0']\n",
    "           \n",
    "        if self.intercept_is_outlier(intercepts_bottom, this_intercept_bottom):\n",
    "            flag_line = False\n",
    "        \n",
    "        #check if radius of curvature (px unit) consistent with previous curvature:\n",
    "        #this_curvature_rad = self.compute_radOfCurvature(coeffs, xmax, xm_per_pix=None, ym_per_pix=None)    \n",
    "        #if self.is_outlier(self.radius_of_curvature_tracker, this_curvature_rad):\n",
    "        #    flag_tracker = False\n",
    "        \n",
    "        #get distance image center to lane line\n",
    "        #if np.abs(dist_2lane) > max_dist:\n",
    "        #    flag_lane = False\n",
    "        #    print('False because of lane distance')\n",
    "        \n",
    "        #if self.is_outlier(self.bestfit['a1'], coeffs['a1']) or self.is_outlier(self.bestfit['a0'], coeffs['a0']): \n",
    "        #    flag_lane = False\n",
    "        #    print('False because of outlier')\n",
    "        #print('Approve Lane:', flag_lane)\n",
    "        #print('**************')\n",
    "        return flag_line\n",
    "        \n",
    "    \n",
    "    def mva_smoothing(self, tracker, weighted=False):\n",
    "        '''\n",
    "        Moving average smoothing of polyfit coefficients \n",
    "        weighted: True, use weighted average \n",
    "                (1a + 1/2b + 1/3c...)/(1+1/2+1/3...) where a is the most recent frame, b 2nd most recent, etc...\n",
    "                False: use mean\n",
    "        '''\n",
    "        if weighted:\n",
    "            if tracker == 'coeffs':\n",
    "                smooth_tracker = {'a2':0, 'a1':0, 'a0': 0}\n",
    "                a2, a1, a0, denominator = 0, 0, 0, 0\n",
    "                #higher weight for latest coefficients frames\n",
    "                \n",
    "                for i in range(len(self.bestfit['a2'])):\n",
    "                    a2 = a2 + self.bestfit['a2'][i]/abs(len(self.bestfit['a2']) - i)\n",
    "                    a1 = a1 + self.bestfit['a1'][i]/abs(len(self.bestfit['a2']) - i)\n",
    "                    a0 = a0 + self.bestfit['a0'][i]/abs(len(self.bestfit['a2']) - i)\n",
    "                    denominator = denominator + 1/abs(len(self.bestfit['a2']) - i)\n",
    "                smooth_tracker['a2'] = a2/denominator\n",
    "                smooth_tracker['a1'] = a1/denominator\n",
    "                smooth_tracker['a0'] = a0/denominator\n",
    "                return smooth_tracker\n",
    "            elif tracker == 'radCurv':\n",
    "                smooth_val, denominator = 0, 0\n",
    "                for i in range(len(self.radOfCurv_tracker)):\n",
    "                    smooth_val = smooth_val + self.radOfCurv_tracker[i]/abs(len(self.radOfCurv_tracker) - i)\n",
    "                    denominator = denominator + 1/abs(len(self.radOfCurv_tracker) - i)\n",
    "                return smooth_val/denominator  \n",
    "        else:\n",
    "            if tracker == 'coeffs':\n",
    "                smooth_coeffs = {'a2':0, 'a1':0, 'a0': 0}\n",
    "                smooth_coeffs['a2'] = np.mean(self.bestfit['a2'])\n",
    "                smooth_coeffs['a1'] = np.mean(self.bestfit['a1'])\n",
    "                smooth_coeffs['a0'] = np.mean(self.bestfit['a0'])\n",
    "                return smooth_coeffs\n",
    "            elif tracker == 'radCurv':\n",
    "                return np.mean(self.radOfCurv_tracker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def perspective_transform(src_pts, dst_pts):\n",
    "    '''\n",
    "    perspective transform\n",
    "    args: source and destination points\n",
    "    return M and Minv\n",
    "    '''\n",
    "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "    Minv = cv2.getPerspectiveTransform(dst_pts, src_pts)\n",
    "    \n",
    "    return {'M': M, 'Minv':Minv}\n",
    "\n",
    "\n",
    "#To confirm that your detected lane lines are real, you might consider:\n",
    "#Checking that they have similar curvature\n",
    "#Checking that they are separated by approximately the right distance horizontally\n",
    "#Checking that they are roughly parallel\n",
    "    \n",
    "    \n",
    "camera_calib = calib_params\n",
    "src_pts = np.float32([[240, 720], [575, 470], [735, 470], [1200, 720]])\n",
    "dst_pts = np.float32([[240, 720], [240, 0], [1200, 0], [1200, 720]])\n",
    "transform_matrix = perspective_transform(src_pts, dst_pts)\n",
    "gradx_thresh=[25, 255]\n",
    "ch_thresh=[50, 255]\n",
    "showMe = 0\n",
    "bottom_crop = -40 #front-end car\n",
    "sliding_window_specs = {'width': 120, 'n_steps': 10} #number of steps vertical steps of sliding window\n",
    "peak_thresh = 10 # if number of hot pixel in window below 50, #consider them as noise and do not attempt to get centroid\n",
    "buffer_sz = 9\n",
    "ym_per_pix = 12/450 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/911 # meters per pixel in x dimensio\n",
    "\n",
    "min_sz = 50\n",
    "apply_MDOutlier = False\n",
    "MD_thresh = 1.8\n",
    "\n",
    "lineLeft = Line(buffer_sz=buffer_sz, showMe=showMe)\n",
    "lineRight = Line(buffer_sz=buffer_sz, showMe=showMe)\n",
    "alpha = None\n",
    "\n",
    "def pipeline(image):\n",
    "    '''\n",
    "    Image processing to highlight lanes\n",
    "    '''\n",
    "    \n",
    "    # Image processing pipeline\n",
    "    process = ImageProcess()\n",
    "    img_sz = (image.shape[1], image.shape[0])\n",
    "    pt_curvature = image.shape[0]\n",
    "    original = image.copy()\n",
    "    image = process.image_correction(image, camera_calib)\n",
    "    if showMe: display(image, 'Apply Camera Correction', color=1)\n",
    "        \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    if showMe: display(gray, 'GRAY', color=0)\n",
    "        \n",
    "    gradx = process.directional_gradient(gray, direction='x', thresh=gradx_thresh )\n",
    "    if showMe: display(gradx, 'Gradient x', color=0)\n",
    "    \n",
    "    ch3_hls_binary = process.color_binary(image, dst_format='HLS', ch=3, ch_thresh=ch_thresh)\n",
    "    if showMe: display(ch3_hls_binary, 'HLS to Binary S ', color=0)\n",
    "        \n",
    "    combined_output = np.zeros_like(gradx)\n",
    "    combined_output[((gradx == 1) | (ch3_hls_binary == 1) )] = 1\n",
    "    if showMe: display(combined_output, 'Combined output', color=0)\n",
    "    \n",
    "    #apply ROI mask\n",
    "    mask = np.zeros_like(combined_output)\n",
    "    vertices = np.array([[(100, 720), (545, 470), (755, 470), (1290, 720)]], dtype=np.int32)\n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, 1)\n",
    "    masked_image = cv2.bitwise_and(combined_output, mask)\n",
    "    if showMe: display(masked_image, 'Masked', color=0)\n",
    "    \n",
    "    #Removing small aggregate of hotpixels\n",
    "    cleaned = morphology.remove_small_objects(masked_image.astype('bool'), min_size=min_sz, connectivity=2)\n",
    "    if showMe: display(cleaned, 'cleaned', color=0)\n",
    "    \n",
    "    warped_img = process.birdView(cleaned*1.0, transform_matrix['M'])\n",
    "    if showMe: display(warped_img, 'Bird View', color=0)\n",
    "    \n",
    "    #adjust image height (remove front-end of car)\n",
    "    warped_img = warped_img[0:bottom_crop, :]\n",
    "    \n",
    "    \n",
    "    if lineRight.line_detected == False:\n",
    "        centroid_starter_right = lineRight.find_starter_centroids(warped_img, x0=warped_img.shape[1]/2, \n",
    "                                                               peak_thresh=peak_thresh, showMe=showMe)\n",
    "        lineRight.starter_centroid = centroid_starter_right['centroid']\n",
    "        lineRight.line_detected = True\n",
    "        \n",
    "    log_lineRight = lineRight.run_sliding_window(warped_img, lineRight.starter_centroid,\n",
    "                                                 sliding_window_specs, showMe=showMe)    \n",
    "        \n",
    "    if lineLeft.line_detected == False:\n",
    "        centroid_starter_left = lineLeft.find_starter_centroids(warped_img, x0=0, peak_thresh=peak_thresh,\n",
    "                                                            showMe=showMe)\n",
    "        lineLeft.starter_centroid = centroid_starter_left['centroid']\n",
    "        lineLeft.line_detected = True\n",
    "        \n",
    "    log_lineLeft = lineLeft.run_sliding_window(warped_img, lineLeft.starter_centroid,\n",
    "                                               sliding_window_specs, showMe=showMe)\n",
    "    \n",
    "    if apply_MDOutlier:\n",
    "        #Remove bi-variate outliers using Mahalanobis Distance\n",
    "        log_lineRight['x'], log_lineRight['y'] = \\\n",
    "                    lineRight.MD_removeOutliers(log_lineRight['x'], log_lineRight['y'], MD_thresh)\n",
    "\n",
    "        log_lineLeft['x'], log_lineLeft['y'] = \\\n",
    "                       lineLeft.MD_removeOutliers(log_lineLeft['x'], log_lineLeft['y'], MD_thresh)\n",
    "    \n",
    "    \n",
    "    #add this frame' hotpixels to allx and ally tracker only if hotpixels detected\n",
    "    #add this frame' hotpixels to allx and ally tracker\n",
    "    if len(log_lineRight['x']) !=0 and len(log_lineLeft['x'])!=0 :\n",
    "        lineRight.update_tracker('hotpixels', log_lineRight)\n",
    "        lineLeft.update_tracker('hotpixels', log_lineLeft)\n",
    "    else:\n",
    "        lineRight.line_detected = False\n",
    "        lineLeft.line_detected = False\n",
    "    \n",
    "\n",
    "    # use all hotpixels accumulated in allx and ally from the last n frames\n",
    "    # allx is of the form [[hotpixels frame1], [hotpixels_frame2], ....]\n",
    "    multiframe_r = {'x': [val for sublist in lineRight.allx for val in sublist],\n",
    "                                            'y': [val for sublist in lineRight.ally for val in sublist] }\n",
    "    \n",
    "    multiframe_l = {'x': [val for sublist in lineLeft.allx for val in sublist],\n",
    "                                            'y': [val for sublist in lineLeft.ally for val in sublist] }\n",
    "    #fit to polynomial in pixel space: right line\n",
    "    fit_lineRight = lineRight.polynomial_fit(multiframe_r)\n",
    "    #fit to polynomial in real space: right line\n",
    "    fit_lineRight_real = lineRight.polynomial_fit({'x': [i*ym_per_pix for i in multiframe_r['x']], \n",
    "                                                   'y': [i*xm_per_pix for i in multiframe_r['y']]})\n",
    "    #fit to polynomial in pixel space: left line\n",
    "    fit_lineLeft = lineLeft.polynomial_fit(multiframe_l)\n",
    "    #fit to polynomial in real space: left line\n",
    "    fit_lineLeft_real = lineLeft.polynomial_fit({'x': [i*ym_per_pix for i in multiframe_l['x']], \n",
    "                                                 'y': [i*xm_per_pix for i in multiframe_l['y']]})\n",
    "    \n",
    "    \n",
    "    # check approval of fitted right line\n",
    "    if lineRight.approve_line(fit_lineRight, xmax=image.shape[0]):\n",
    "        # update trackers\n",
    "        lineRight.update_tracker('bestfit', fit_lineRight)\n",
    "        lineRight.update_tracker('bestfit_real', fit_lineRight_real)\n",
    "        radOfCurv_r = lineRight.compute_radOfCurvature(fit_lineRight_real, pt_curvature*ym_per_pix)\n",
    "        lineRight.update_tracker('radOfCurvature', radOfCurv_r)\n",
    "    else:\n",
    "        # use coeffs of the previous frame \n",
    "        fit_lineRight = {'a2': lineRight.bestfit['a2'][-1], 'a1': lineRight.bestfit['a1'][-1],\n",
    "                        'a0': lineRight.bestfit['a0'][-1]}\n",
    "        #use radius of curvature of previous frame\n",
    "        radOfCurv_r = lineRight.radOfCurv_tracker[-1]\n",
    "        \n",
    "    # check approval of fitted left line\n",
    "    if lineLeft.approve_line(fit_lineLeft, xmax=image.shape[0]):\n",
    "        #update trackers\n",
    "        lineLeft.update_tracker('bestfit', fit_lineLeft)\n",
    "        lineLeft.update_tracker('bestfit_real', fit_lineLeft_real)\n",
    "        radOfCurv_l = lineLeft.compute_radOfCurvature(fit_lineLeft_real, pt_curvature*ym_per_pix)\n",
    "        lineLeft.update_tracker('radOfCurvature', radOfCurv_l)\n",
    "    else:\n",
    "        # use coeffs of the previous frame \n",
    "        fit_lineLeft = {'a2': lineLeft.bestfit['a2'][-1], \n",
    "                         'a1': lineLeft.bestfit['a1'][-1],\n",
    "                         'a0': lineLeft.bestfit['a0'][-1]}\n",
    "        #use radius of curvature of previous frame\n",
    "        radOfCurv_l = lineLeft.radOfCurv_tracker[-1]\n",
    "        \n",
    "    \n",
    "    #display lane and best polynomial fits\n",
    "    var_pts = np.linspace(0, image.shape[0]-1, num=image.shape[0])\n",
    "    if showMe:\n",
    "        #show currentframe\n",
    "        plt.imshow(warped_img, cmap='gray')\n",
    "        #show hotpixels accumulated during last n frames\n",
    "        plt.scatter(multiframe_r['y'], multiframe_r['x'], color='cyan', s=0.1, alpha=0.1)\n",
    "        plt.scatter(multiframe_l['y'], multiframe_l['x'], color='cyan', s=0.1, alpha=0.1)\n",
    "    \n",
    "        #Show best fit on multiframe\n",
    "        pred_lineRight = lineRight.predict_line(0, image.shape[0], fit_lineRight)\n",
    "        pred_lineLeft = lineLeft.predict_line(0, image.shape[0], fit_lineLeft)\n",
    "        plt.plot(pred_lineLeft[:,1], pred_lineLeft[:,0], 'r-', label='multiframe', linewidth=3)\n",
    "        plt.plot(pred_lineRight[:,1], pred_lineRight[:,0], 'r-', label='multiframe', linewidth=3)\n",
    "        plt.title('accum_fr (cyan) - bestfit on 1fr (b) - bestfit acc_fr (r)')\n",
    "        \n",
    "        # Show best fit on current single frame \n",
    "        fit_lineRight_singleframe = lineRight.polynomial_fit(log_lineRight)\n",
    "        fit_lineLeft_singleframe = lineLeft.polynomial_fit(log_lineLeft)\n",
    "        var_pts = np.linspace(0, image.shape[0]-1, num=image.shape[0])\n",
    "        pred_lineLeft_singleframe = lineLeft.predict_line(0, image.shape[0], fit_lineLeft_singleframe)\n",
    "        pred_lineRight_singleframe = lineRight.predict_line(0, image.shape[0], fit_lineRight_singleframe)\n",
    "        plt.plot(pred_lineLeft_singleframe[:,1], pred_lineLeft_singleframe[:,0], 'b-', label='singleframe', linewidth=1)\n",
    "        plt.plot(pred_lineRight_singleframe[:,1], pred_lineRight_singleframe[:,0], 'b-', label='singleframe', linewidth=1)\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    #smoothing fitcoeffs and radis of Curvature\n",
    "    smoothfit_lineLeft = lineLeft.mva_smoothing('coeffs', weighted=True)\n",
    "    radCurv_smooth_lineLeft = lineLeft.mva_smoothing('radCurv', weighted=True)\n",
    "    smoothfit_lineRight = lineRight.mva_smoothing('coeffs', weighted=True)\n",
    "    radCurv_smooth_lineRight = lineRight.mva_smoothing('radCurv', weighted=True)\n",
    "    #predicted smoothed lane left lane\n",
    "    pred_smooth_lineLeft = lineLeft.predict_line(0, image.shape[0], smoothfit_lineLeft)\n",
    "    pred_smooth_lineRight = lineRight.predict_line(0, image.shape[0], smoothfit_lineRight)\n",
    "    \n",
    "    if showMe:\n",
    "        #display lane and predicted lines with smoothing\n",
    "        plt.imshow(warped_img, cmap='gray')\n",
    "        plt.plot(pred_smooth_lineLeft[:,1], pred_smooth_lineLeft[:,0], 'r-')\n",
    "        plt.plot(pred_smooth_lineRight[:,1], pred_smooth_lineRight[:,0], 'r-')\n",
    "        plt.title('best fit with smoothing')\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###############\n",
    "    # estimate offsetclose to driver (bottom of image)\n",
    "    center_of_lane = (pred_smooth_lineLeft[:,1][-1] +  pred_smooth_lineRight[:,1][-1])/2\n",
    "    offset = (image.shape[1]/2 - center_of_lane ) * xm_per_pix\n",
    "    side_pos = 'right'\n",
    "    if offset < 0:\n",
    "        side_pos = 'left'\n",
    "\n",
    "\n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(gray).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_fitx = smoothfit_lineLeft['a2']*var_pts**2 + smoothfit_lineLeft['a1']*var_pts + smoothfit_lineLeft['a0']\n",
    "    right_fitx = smoothfit_lineRight['a2']*var_pts**2 + smoothfit_lineRight['a1']*var_pts + smoothfit_lineRight['a0']\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, var_pts]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, var_pts])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    cv2.putText(color_warp, '|', (int(image.shape[1]/2), image.shape[0]-10), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 8)\n",
    "    #middle of the lane\n",
    "    cv2.putText(color_warp, '|', (int(center_of_lane), image.shape[0]-10), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 8)\n",
    "    newwarp = cv2.warpPerspective(color_warp, transform_matrix['Minv'], (image.shape[1], image.shape[0]))\n",
    "    result = cv2.addWeighted(image, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    ##############\n",
    "    # Radius of Curvature\n",
    "    # Determine polynomial parameters in real space\n",
    "    ####fit_lineRight = .polynomial_fit(multiframe_r)\n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    if showMe:\n",
    "        plt.imshow(result)\n",
    "        plt.show()\n",
    "    \n",
    "    average_radCurv = (radCurv_smooth_lineLeft + radCurv_smooth_lineRight)/2\n",
    "    cv2.putText(result, 'Vehicle is '+ str(round(offset, 3)) +'m ' +side_pos +' of center',\n",
    "                (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), thickness=2)\n",
    "    cv2.putText(result, 'Radius of curvature :'+ str(round(average_radCurv))+ 'm', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), thickness=2)\n",
    "    \n",
    "    if showMe:\n",
    "        plt.title('Final Result')\n",
    "        plt.imshow(result)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    return result.astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Line Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video challenge_solution.mp4\n",
      "[MoviePy] Writing video challenge_solution.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 485/485 [02:33<00:00,  3.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: challenge_solution.mp4 \n",
      "\n",
      "CPU times: user 4min 40s, sys: 34.5 s, total: 5min 15s\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "video_output = 'challenge_solution.mp4'\n",
    "clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "white_clip = clip1.fl_image(pipeline) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
